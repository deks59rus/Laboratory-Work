{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Форматы данных (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. \"Лекция 4: Форматы данных\"\n",
    "* https://docs.python.org/3/library/json.html\n",
    "* https://docs.python.org/3/library/pickle.html\n",
    "* https://www.crummy.com/software/BeautifulSoup/bs4/doc.ru/bs4ru.html\n",
    "* Уэс Маккини. Python и анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Вывести все адреса электронной почты, содержащиеся в адресной книге `addres-book.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Вывести телефоны, содержащиеся в адресной книге `addres-book.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. По данным из файла `addres-book-q.xml` сформировать список словарей с телефонами каждого из людей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа №4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезные функции для работы с файловой системой:\n",
    "\n",
    "os.getcwd() - получение текущего пути\n",
    "\n",
    "os.chdir() - изменение текущего пути\n",
    "\n",
    "os.mkdir() - создание новой директории\n",
    "\n",
    "os.rename() - переименование директории\n",
    "\n",
    "os.rmdir() - удаление директории\n",
    "\n",
    "os.walk() - получение содержимого директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\den10\\Desktop\\Технологии обработки данных\\Лабораторные работы\\Laboratory-Work\\Лабораторные работы\\3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['03_data_files_Галкин Денис Сергеевич.ipynb',\n",
       " 'job_people.json',\n",
       " 'job_people.pickle',\n",
       " 'recipes_sample_with_filled_nsteps.csv',\n",
       " 'steps_sample.json',\n",
       " 'steps_sample2.json']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "cwd2 = os.getcwd()\n",
    "onlyfiles = [f for f in listdir(cwd2) if isfile(join(cwd2, f))]\n",
    "print(cwd2)\n",
    "onlyfiles\n",
    "\n",
    "#cwd=os.getcwd()\n",
    "\n",
    "\n",
    "# рекурсивный обход дочерних директорий и файлов в них:\n",
    "#for root, dirs, files in os.walk(cwd):\n",
    "#    print(f\"{root}, dirs: {dirs}, files: {files}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Считайте файл `contributors_sample.json`. Воспользовавшись модулем `json`, преобразуйте содержимое файла в соответствующие объекты python. Выведите на экран информацию о первых 3 пользователях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "\n",
      "1 пользователь:\n",
      "username : uhebert\n",
      "name : Lindsey Nguyen\n",
      "sex : F\n",
      "address : 01261 Cameron Spring\n",
      "Taylorfurt, AK 97791\n",
      "mail : jsalazar@gmail.com\n",
      "jobs : ['Energy engineer', 'Engineer, site', 'Environmental health practitioner', 'Biomedical scientist', 'Jewellery designer']\n",
      "id : 35193\n",
      "\n",
      "2 пользователь:\n",
      "username : vickitaylor\n",
      "name : Cheryl Lewis\n",
      "sex : F\n",
      "address : 66992 Welch Brooks\n",
      "Marshallshire, ID 56004\n",
      "mail : bhudson@gmail.com\n",
      "jobs : ['Music therapist', 'Volunteer coordinator', 'Designer, interior/spatial']\n",
      "id : 91970\n",
      "\n",
      "3 пользователь:\n",
      "username : sheilaadams\n",
      "name : Julia Allen\n",
      "sex : F\n",
      "address : Unit 1632 Box 2971\n",
      "DPO AE 23297\n",
      "mail : darren44@yahoo.com\n",
      "jobs : ['Management consultant', 'Engineer, structural', 'Lecturer, higher education', 'Theatre manager', 'Designer, textile']\n",
      "id : 1848091\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "cwd=os.getcwd()\n",
    "\n",
    "with open(cwd+'\\\\data\\\\contributors_sample.json', 'r', encoding='UTF-8') as fp:\n",
    "        # Чтение файла 'data.json' и преобразование\n",
    "        # данных JSON в объект Python\n",
    "        data = json.load(fp)\n",
    "print(type(data[0]))\n",
    "def PrintFirstData(source, n):\n",
    "    for i in range(n):    \n",
    "        print(f\"\\n{i+1} пользователь:\")\n",
    "        for a in source[i]:\n",
    "            print(a, source[i][a], sep=\" : \")\n",
    "        i+=1\n",
    "PrintFirstData(data, 3)\n",
    "#print(\"Второй пользователь:\\n\",data[1])\n",
    "#print(\"Третий пользователь:\\n\",data[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Выведите уникальные почтовые домены, содержащиеся в почтовых адресах людей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yahoo.com', 'gmail.com', 'hotmail.com']\n"
     ]
    }
   ],
   "source": [
    "domens=[]#инициализируем пустой список доменов\n",
    "for user in data:\n",
    "    s=user['mail']#находим значение в словаре по ключу \"mail\"\n",
    "    s=s[s.find(\"@\") + 1:]#срезаем строку по \"@\" для получения почтового домена\n",
    "    domens.append(s)\n",
    "unic_domens= list(set(domens))#находим уникальные значения\n",
    "print(unic_domens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая по `username` ищет человека и выводит информацию о нем. Если пользователь с заданным `username` отсутствует, возбудите исключение `ValueError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username : sheilaadams\n",
      "name : Julia Allen\n",
      "sex : F\n",
      "address : Unit 1632 Box 2971\n",
      "DPO AE 23297\n",
      "mail : darren44@yahoo.com\n",
      "jobs : ['Management consultant', 'Engineer, structural', 'Lecturer, higher education', 'Theatre manager', 'Designer, textile']\n",
      "id : 1848091\n",
      "\n",
      "username : vickitaylor\n",
      "name : Cheryl Lewis\n",
      "sex : F\n",
      "address : 66992 Welch Brooks\n",
      "Marshallshire, ID 56004\n",
      "mail : bhudson@gmail.com\n",
      "jobs : ['Music therapist', 'Volunteer coordinator', 'Designer, interior/spatial']\n",
      "id : 91970\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Такого пользователя в словаре нет!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32688\\826743774.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mFind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sheilaadams'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mFind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vickitaylor'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mFind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'111'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32688\\826743774.py\u001b[0m in \u001b[0;36mFind\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m  \u001b[0misnotinDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Такого пользователя в словаре нет!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mFind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sheilaadams'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Такого пользователя в словаре нет!"
     ]
    }
   ],
   "source": [
    "def Find(key):\n",
    "    isnotinDict= True\n",
    "    for user in data:\n",
    "        if user[\"username\"] == key:\n",
    "            isnotinDict= False\n",
    "            for info in user:\n",
    "                print(info, user[info], sep=\" : \")\n",
    "            print()\n",
    "    if  isnotinDict:\n",
    "        raise ValueError('Такого пользователя в словаре нет!')\n",
    "            \n",
    "Find('sheilaadams')\n",
    "Find('vickitaylor')\n",
    "Find('111')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Посчитайте, сколько мужчин и женщин присутсвует в этом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мужчин: 2064\n",
      "Женщин: 2136\n"
     ]
    }
   ],
   "source": [
    "count_male, count_female= 0,0\n",
    "for user in data:\n",
    "    if user['sex']== \"F\":\n",
    "        count_female+=1\n",
    "    else:\n",
    "        count_male+=1\n",
    "print(f\"Мужчин: {count_male}\\nЖенщин: {count_female}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Создайте `pd.DataFrame` `contributors`, имеющий столбцы `id`, `username` и `sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35193</td>\n",
       "      <td>uhebert</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91970</td>\n",
       "      <td>vickitaylor</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1848091</td>\n",
       "      <td>sheilaadams</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50969</td>\n",
       "      <td>nicole82</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>676820</td>\n",
       "      <td>jean67</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>423555</td>\n",
       "      <td>stevenspencer</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>35251</td>\n",
       "      <td>rwilliams</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>135887</td>\n",
       "      <td>lmartinez</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>212714</td>\n",
       "      <td>brendahill</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>344321</td>\n",
       "      <td>mistyray</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       username sex\n",
       "0       35193        uhebert   F\n",
       "1       91970    vickitaylor   F\n",
       "2     1848091    sheilaadams   F\n",
       "3       50969       nicole82   F\n",
       "4      676820         jean67   M\n",
       "...       ...            ...  ..\n",
       "4195   423555  stevenspencer   F\n",
       "4196    35251      rwilliams   M\n",
       "4197   135887      lmartinez   F\n",
       "4198   212714     brendahill   M\n",
       "4199   344321       mistyray   F\n",
       "\n",
       "[4200 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "contributors= pd.DataFrame(data).drop(['name', 'address', 'mail','jobs'], axis=1)[[\"id\",\"username\",\"sex\"]]\n",
    "contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 Загрузите данные из файла `recipes_sample.csv` (__ЛР2__) в таблицу `recipes`. Объедините `recipes` с таблицей `contributors` с сохранением строк в том случае, если информация о человеке отсутствует в JSON-файле. Для скольких человек информация отсутствует? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 0 to 29999\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   id_x            14941 non-null  object        \n",
      " 1   username        14941 non-null  object        \n",
      " 2   sex             14941 non-null  object        \n",
      " 3   name            30000 non-null  object        \n",
      " 4   id_y            30000 non-null  int64         \n",
      " 5   minutes         30000 non-null  int64         \n",
      " 6   contributor_id  30000 non-null  int64         \n",
      " 7   submitted       30000 non-null  datetime64[ns]\n",
      " 8   n_steps         18810 non-null  float64       \n",
      " 9   description     29377 non-null  object        \n",
      " 10  n_ingredients   21120 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(3), object(5)\n",
      "memory usage: 2.7+ MB\n",
      "None\n",
      "для 4204 человек информация отсутствует\n",
      "Объединенная таблица представленна ниже:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>username</th>\n",
       "      <th>sex</th>\n",
       "      <th>name</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>description</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1545.0</td>\n",
       "      <td>bushjohn</td>\n",
       "      <td>F</td>\n",
       "      <td>boston cream pie</td>\n",
       "      <td>135</td>\n",
       "      <td>1545</td>\n",
       "      <td>1999-08-24</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>betty crocker s southwestern guacamole dip</td>\n",
       "      <td>125</td>\n",
       "      <td>1538</td>\n",
       "      <td>1999-09-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>174711.0</td>\n",
       "      <td>schultzsteven</td>\n",
       "      <td>M</td>\n",
       "      <td>black coffee barbecue sauce</td>\n",
       "      <td>30</td>\n",
       "      <td>174711</td>\n",
       "      <td>1999-09-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it's great to know folks like this sauce so mu...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1576.0</td>\n",
       "      <td>ktaylor</td>\n",
       "      <td>M</td>\n",
       "      <td>brown rice and vegetable pilaf</td>\n",
       "      <td>150</td>\n",
       "      <td>1576</td>\n",
       "      <td>1999-09-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this is good with almost anything... robb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blueberry buttertarts</td>\n",
       "      <td>40</td>\n",
       "      <td>1556</td>\n",
       "      <td>1999-09-12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536547</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cauliflower ceviche</td>\n",
       "      <td>45</td>\n",
       "      <td>2002234079</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>15.0</td>\n",
       "      <td>a healthy ceviche - a perfect appetizer for pa...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miracle home made puff pastry</td>\n",
       "      <td>35</td>\n",
       "      <td>2002234259</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>17.0</td>\n",
       "      <td>puff pastry that you can make in minutes? at h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536728</th>\n",
       "      <td>1052873.0</td>\n",
       "      <td>cookmisty</td>\n",
       "      <td>F</td>\n",
       "      <td>gluten free  vegemite</td>\n",
       "      <td>2</td>\n",
       "      <td>1052873</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gluten free vegemite-like stuff.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536729</th>\n",
       "      <td>1052873.0</td>\n",
       "      <td>cookmisty</td>\n",
       "      <td>F</td>\n",
       "      <td>creole watermelon feta salad</td>\n",
       "      <td>10</td>\n",
       "      <td>1052873</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>spicy watermelon salad. from tony chachere's s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536747</th>\n",
       "      <td>2002247884.0</td>\n",
       "      <td>martin01</td>\n",
       "      <td>F</td>\n",
       "      <td>lemon pom pom cake</td>\n",
       "      <td>210</td>\n",
       "      <td>2002247884</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>51.0</td>\n",
       "      <td>by far one of my most joyous cake creations, t...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_x       username  sex  \\\n",
       "id_y                                       \n",
       "48            1545.0       bushjohn    F   \n",
       "55               NaN            NaN  NaN   \n",
       "66          174711.0  schultzsteven    M   \n",
       "91            1576.0        ktaylor    M   \n",
       "94               NaN            NaN  NaN   \n",
       "...              ...            ...  ...   \n",
       "536547           NaN            NaN  NaN   \n",
       "536610           NaN            NaN  NaN   \n",
       "536728     1052873.0      cookmisty    F   \n",
       "536729     1052873.0      cookmisty    F   \n",
       "536747  2002247884.0       martin01    F   \n",
       "\n",
       "                                              name  minutes  contributor_id  \\\n",
       "id_y                                                                          \n",
       "48                                boston cream pie      135            1545   \n",
       "55      betty crocker s southwestern guacamole dip      125            1538   \n",
       "66                     black coffee barbecue sauce       30          174711   \n",
       "91                  brown rice and vegetable pilaf      150            1576   \n",
       "94                           blueberry buttertarts       40            1556   \n",
       "...                                            ...      ...             ...   \n",
       "536547                         cauliflower ceviche       45      2002234079   \n",
       "536610               miracle home made puff pastry       35      2002234259   \n",
       "536728                       gluten free  vegemite        2         1052873   \n",
       "536729                creole watermelon feta salad       10         1052873   \n",
       "536747                          lemon pom pom cake      210      2002247884   \n",
       "\n",
       "        submitted  n_steps                                        description  \\\n",
       "id_y                                                                            \n",
       "48     1999-08-24     32.0                                                NaN   \n",
       "55     1999-09-15      NaN                                                NaN   \n",
       "66     1999-09-10      NaN  it's great to know folks like this sauce so mu...   \n",
       "91     1999-09-06      NaN          this is good with almost anything... robb   \n",
       "94     1999-09-12      8.0                                                NaN   \n",
       "...           ...      ...                                                ...   \n",
       "536547 2018-07-30     15.0  a healthy ceviche - a perfect appetizer for pa...   \n",
       "536610 2018-07-31     17.0  puff pastry that you can make in minutes? at h...   \n",
       "536728 2018-08-11      NaN                   gluten free vegemite-like stuff.   \n",
       "536729 2018-08-11      4.0  spicy watermelon salad. from tony chachere's s...   \n",
       "536747 2018-08-15     51.0  by far one of my most joyous cake creations, t...   \n",
       "\n",
       "        n_ingredients  \n",
       "id_y                   \n",
       "48               15.0  \n",
       "55                5.0  \n",
       "66               11.0  \n",
       "91                NaN  \n",
       "94                NaN  \n",
       "...               ...  \n",
       "536547            8.0  \n",
       "536610            NaN  \n",
       "536728            3.0  \n",
       "536729            NaN  \n",
       "536747           20.0  \n",
       "\n",
       "[30000 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes=pd.read_csv('C:\\\\Users\\\\den10\\\\Desktop\\\\Технологии обработки данных\\\\Лабораторные работы\\\\Laboratory-Work\\\\Лабораторные работы\\\\2\\\\data\\\\recipes_sample.csv', encoding='ISO-8859–1', parse_dates= ['submitted'])\n",
    "merged_table= pd.merge(contributors, recipes, left_on= \"id\", right_on = 'contributor_id', how='right')\n",
    "merged_table[['id_x']]=merged_table[['id_x']].astype(object)\n",
    "print(merged_table.info())\n",
    "merged_table=merged_table.sort_values(by=\"id_y\").set_index(\"id_y\")\n",
    "table_with_empty_user=merged_table[merged_table['username'].isnull()]\n",
    "count_empty_user=table_with_empty_user.groupby(\"contributor_id\").count().shape[0]\n",
    "print(f'для {count_empty_user} человек информация отсутствует')\n",
    "print('Объединенная таблица представленна ниже:')\n",
    "merged_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе файла `contributors_sample.json` создайте словарь следующего вида: \n",
    "```\n",
    "{\n",
    "    должность: [список username людей, занимавших эту должность]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uhebert',\n",
       " 'nancy12',\n",
       " 'andrea03',\n",
       " 'catherineross',\n",
       " 'wesley32',\n",
       " 'natalieross',\n",
       " 'rossdoris',\n",
       " 'christophersmith',\n",
       " 'dbooker',\n",
       " 'ericarobertson',\n",
       " 'trantricia',\n",
       " 'tpugh',\n",
       " 'jasonvelez',\n",
       " 'samantha36',\n",
       " 'brandidaniels',\n",
       " 'tenglish',\n",
       " 'reyesbrett',\n",
       " 'austin18',\n",
       " 'vjohnson',\n",
       " 'zmejia',\n",
       " 'daniel04',\n",
       " 'cynthia20',\n",
       " 'morgan15',\n",
       " 'avaldez',\n",
       " 'jessica92',\n",
       " 'laurieholloway',\n",
       " 'baileyvictoria']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "dct = defaultdict(list)\n",
    "for user in data:\n",
    "    jobs = user[\"jobs\"]\n",
    "    username = user[\"username\"]\n",
    "    for job in jobs:\n",
    "        dct[job].append(username)\n",
    "result_dictionary= dict(dct)\n",
    "result_dictionary['Engineer, site']#Проверка: Должность - список логинов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Сохраните результаты в файл `job_people.pickle` и в файл `job_people.json` с использованием форматов pickle и JSON соответственно. Сравните объемы получившихся файлов. При сохранении в JSON укажите аргумент `indent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cwd=os.getcwd()\n",
    "#cwd\n",
    "with open('C:\\\\Users\\\\den10\\\\Desktop\\\\Технологии обработки данных\\\\Лабораторные работы\\\\Laboratory-Work\\\\Лабораторные работы\\\\3\\\\job_people.pickle', 'wb') as job_people_out1:\n",
    "    pickle.dump(result_dictionary, job_people_out1)\n",
    "\n",
    "with open('C:\\\\Users\\\\den10\\\\Desktop\\\\Технологии обработки данных\\\\Лабораторные работы\\\\Laboratory-Work\\\\Лабораторные работы\\\\3\\\\job_people.json', 'w') as job_people_out2:\n",
    "    json.dump(result_dictionary, job_people_out2, indent=2)"
   ]
  },
  {
   "attachments": {
    "Screenshot_17.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot_17.png](attachment:Screenshot_17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Считайте файл `job_people.pickle` и продемонстрируйте, что данные считались корректно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uhebert', 'lopezantonio', 'ojames', 'leonnicole', 'daltonmelissa', 'joseph26', 'donnacurry', 'stewartpamela', 'williamsbill', 'garciaduane', 'megan77', 'victoriachavez', 'richardherman', 'elainerodriguez', 'mark85', 'dali', 'bfernandez', 'heatherphillips', 'sdaniel', 'brandigreen', 'zachary61', 'sarahleonard', 'harrisonjeffery']\n"
     ]
    }
   ],
   "source": [
    "with open('C:\\\\Users\\\\den10\\\\Desktop\\\\Технологии обработки данных\\\\Лабораторные работы\\\\Laboratory-Work\\\\Лабораторные работы\\\\3\\\\job_people.pickle', 'rb') as f:\n",
    "    readed_data = pickle.load(f)\n",
    "print(readed_data['Jewellery designer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 По данным файла `steps_sample.xml` сформируйте словарь с шагами по каждому рецепту вида `{id_рецепта: [\"шаг1\", \"шаг2\"]}`. Сохраните этот словарь в файл `steps_sample.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранение словаря проведено успешно!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "path='C:\\\\Users\\\\den10\\\\Desktop\\\\Технологии обработки данных\\\\Лабораторные работы\\\\Laboratory-Work\\\\Лабораторные работы\\\\3\\\\data\\\\steps_sample.xml'\n",
    "with open(path, 'r') as f:\n",
    "     bs_data = BeautifulSoup(f, \"xml\")\n",
    "recipes_data = bs_data.find_all('recipe')\n",
    "steps = dict()\n",
    "for recipe in recipes_data:\n",
    "    steps[recipe.id.text]= recipe.steps.getText('|', strip=True).split(sep='|')\n",
    "with open('C:\\\\Users\\\\den10\\\\Desktop\\\\Технологии обработки данных\\\\Лабораторные работы\\\\Laboratory-Work\\\\Лабораторные работы\\\\3\\\\steps_sample.json', 'w') as r1:\n",
    "    json.dump(steps, r1, indent=0)\n",
    "print(\"Сохранение словаря проведено успешно!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 По данным файла `steps_sample.xml` сформируйте словарь следующего вида: `кол-во_шагов_в_рецепте: [список_id_рецептов]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "id_by_steps = defaultdict(list)\n",
    "for recipe in recipes_data:\n",
    "    id_by_steps[len(recipe.steps.getText('|', strip=True).split(sep='|'))].append(recipe.id.text)\n",
    "#with open('C:\\\\Users\\\\den10\\\\Desktop\\\\Технологии обработки данных\\\\Лабораторные работы\\\\Laboratory-Work\\\\Лабораторные работы\\\\3\\\\steps_sample2.json', 'w') as r2:\n",
    "#    json.dump(id_by_steps, r2, indent=0)\n",
    "#print(\"Сохранение словаря проведено успешно!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['310570',\n",
       " '392181',\n",
       " '51546',\n",
       " '56109',\n",
       " '336218',\n",
       " '321405',\n",
       " '195558',\n",
       " '321190',\n",
       " '36961',\n",
       " '279328',\n",
       " '234964',\n",
       " '414937',\n",
       " '90995']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_by_steps[38]#проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Получите список рецептов, в этапах выполнения которых есть информация о времени (часы или минуты). Для отбора подходящих рецептов обратите внимание на атрибуты соответствующих тэгов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ПРОВЕРКА:\n",
      "Всего рецептов:30000\n",
      "В 23469 рецептах есть этапы с информацией о времени.\n",
      "Первые 100 id рецептов, которые содержат информацию о времени: \n",
      "[524289, 131082, 131087, 131090, 262166, 131096, 131107, 131109, 262188, 48, 55, 262207, 131138, 66, 393286, 262214, 262219, 131149, 91, 94, 131173, 131185, 393340, 131206, 262285, 262293, 153, 393375, 524456, 176, 181, 262325, 262327, 186, 262330, 393409, 262340, 203, 262348, 131275, 524495, 393433, 131295, 224, 393448, 131311, 240, 262386, 246, 131322, 262400, 393496, 288, 289, 131364, 131385, 314, 318, 321, 393538, 131408, 337, 393554, 131423, 131429, 360, 373, 378, 379, 381, 262526, 262531, 524675, 131461, 393609, 131471, 262550, 131483, 262564, 393637, 131497, 262577, 262585, 393658, 445, 524744, 262605, 465, 469, 131542, 262625, 262627, 131558, 131567, 524789, 502, 504, 131587, 131602, 393750]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "with_hours=bs_data.find_all(\"step\", attrs={'has_hours': 1})\n",
    "with_minutes=bs_data.find_all(\"step\", attrs={'has_minutes': 1})\n",
    "ids= list()\n",
    "for recipe in with_hours:\n",
    "    ids.append(int(recipe.parent.parent.id.text))\n",
    "for recipe in with_minutes:\n",
    "    ids.append(int(recipe.parent.parent.id.text))\n",
    "ids= (list(set(ids)))\n",
    "print(f\"ПРОВЕРКА:\\nВсего рецептов:{len(recipes_data)}\")\n",
    "print(f\"В {len(ids)} рецептах есть этапы с информацией о времени.\")\n",
    "print(\"Первые 100 id рецептов, которые содержат информацию о времени: \")\n",
    "print(ids[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Загрузите данные из файла `recipes_sample.csv` (__ЛР2__) в таблицу `recipes`. Для строк, которые содержат пропуски в столбце `n_steps`, заполните этот столбец на основе файла  `steps_sample.xml`. Строки, в которых столбец `n_steps` заполнен, оставьте без изменений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\den10\\AppData\\Local\\Temp\\ipykernel_32688\\680555793.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a['n_steps'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>description</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>44123</td>\n",
       "      <td>90</td>\n",
       "      <td>35193</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>11.0</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>67664</td>\n",
       "      <td>10</td>\n",
       "      <td>91970</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>38798</td>\n",
       "      <td>30</td>\n",
       "      <td>1533</td>\n",
       "      <td>2002-08-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>these were so go, it surprised even me.</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>35173</td>\n",
       "      <td>45</td>\n",
       "      <td>22724</td>\n",
       "      <td>2002-07-27</td>\n",
       "      <td>7.0</td>\n",
       "      <td>my sister-in-law made these for us at a family...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>84797</td>\n",
       "      <td>25</td>\n",
       "      <td>4470</td>\n",
       "      <td>2004-02-23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>zurie s holey rustic olive and cheddar bread</td>\n",
       "      <td>267661</td>\n",
       "      <td>80</td>\n",
       "      <td>200862</td>\n",
       "      <td>2007-11-25</td>\n",
       "      <td>16.0</td>\n",
       "      <td>this is based on a french recipe but i changed...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>zwetschgenkuchen  bavarian plum cake</td>\n",
       "      <td>386977</td>\n",
       "      <td>240</td>\n",
       "      <td>177443</td>\n",
       "      <td>2009-08-24</td>\n",
       "      <td>22.0</td>\n",
       "      <td>this is a traditional fresh plum cake, thought...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>zwiebelkuchen   southwest german onion cake</td>\n",
       "      <td>103312</td>\n",
       "      <td>75</td>\n",
       "      <td>161745</td>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>10.0</td>\n",
       "      <td>this is a traditional late summer early fall s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>zydeco soup</td>\n",
       "      <td>486161</td>\n",
       "      <td>60</td>\n",
       "      <td>227978</td>\n",
       "      <td>2012-08-29</td>\n",
       "      <td>7.0</td>\n",
       "      <td>this is a delicious soup that i originally fou...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>cookies by design   cookies on a stick</td>\n",
       "      <td>298512</td>\n",
       "      <td>29</td>\n",
       "      <td>506822</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>9.0</td>\n",
       "      <td>i've heard of the 'cookies by design' company,...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name      id  minutes  \\\n",
       "0             george s at the cove  black bean soup   44123       90   \n",
       "1                healthy for them  yogurt popsicles   67664       10   \n",
       "2                      i can t believe it s spinach   38798       30   \n",
       "3                              italian  gut busters   35173       45   \n",
       "4          love is in the air  beef fondue   sauces   84797       25   \n",
       "...                                             ...     ...      ...   \n",
       "29995  zurie s holey rustic olive and cheddar bread  267661       80   \n",
       "29996          zwetschgenkuchen  bavarian plum cake  386977      240   \n",
       "29997   zwiebelkuchen   southwest german onion cake  103312       75   \n",
       "29998                                   zydeco soup  486161       60   \n",
       "29999        cookies by design   cookies on a stick  298512       29   \n",
       "\n",
       "       contributor_id  submitted  n_steps  \\\n",
       "0               35193 2002-10-25     11.0   \n",
       "1               91970 2003-07-26      3.0   \n",
       "2                1533 2002-08-29      5.0   \n",
       "3               22724 2002-07-27      7.0   \n",
       "4                4470 2004-02-23      4.0   \n",
       "...               ...        ...      ...   \n",
       "29995          200862 2007-11-25     16.0   \n",
       "29996          177443 2009-08-24     22.0   \n",
       "29997          161745 2004-11-03     10.0   \n",
       "29998          227978 2012-08-29      7.0   \n",
       "29999          506822 2008-04-15      9.0   \n",
       "\n",
       "                                             description  n_ingredients  \n",
       "0      an original recipe created by chef scott meska...           18.0  \n",
       "1      my children and their friends ask for my homem...            NaN  \n",
       "2                these were so go, it surprised even me.            8.0  \n",
       "3      my sister-in-law made these for us at a family...            NaN  \n",
       "4      i think a fondue is a very romantic casual din...            NaN  \n",
       "...                                                  ...            ...  \n",
       "29995  this is based on a french recipe but i changed...           10.0  \n",
       "29996  this is a traditional fresh plum cake, thought...           11.0  \n",
       "29997  this is a traditional late summer early fall s...            NaN  \n",
       "29998  this is a delicious soup that i originally fou...            NaN  \n",
       "29999  i've heard of the 'cookies by design' company,...           10.0  \n",
       "\n",
       "[30000 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "recipes=pd.read_csv('C:/Users/den10/Desktop/Технологии обработки данных/Лабораторные работы/Laboratory-Work/Лабораторные работы/2/data/recipes_sample.csv', encoding='ISO-8859–1', parse_dates= ['submitted'])\n",
    "steps2 = dict()\n",
    "for recipe in recipes_data:\n",
    "    steps2[recipe.id.text]= len(recipe.steps.getText('|', strip=True).split(sep='|'))\n",
    "a=recipes[recipes['n_steps'].isna()]\n",
    "a['n_steps'].fillna(0, inplace=True)\n",
    "a=a.reset_index(drop=True)\n",
    "for i in range(a.shape[0]):\n",
    "    a.loc[i, 'n_steps']= steps2[str(a.loc[i, 'id'])]\n",
    "#a.replace(0, np.nan, inplace=True)\n",
    "merge_table= pd.merge(recipes,a[['n_steps', 'id']], left_on=\"id\", right_on=\"id\", how='left')\n",
    "merge_table.loc[merge_table['n_steps_x'].isna(), 'n_steps_x'] = merge_table.loc[:, 'n_steps_y']\n",
    "merge_table.drop('n_steps_y', axis=1, inplace=True)\n",
    "merge_table.rename(columns={'n_steps_x': 'n_steps'}, inplace=True)\n",
    "merge_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 Проверьте, содержит ли столбец `n_steps` пропуски. Если нет, то преобразуйте его к целочисленному типу и сохраните результаты в файл `recipes_sample_with_filled_nsteps.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False - n_steps не содержит пропусков\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 0 to 29999\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   name            30000 non-null  object        \n",
      " 1   id              30000 non-null  int64         \n",
      " 2   minutes         30000 non-null  int64         \n",
      " 3   contributor_id  30000 non-null  int64         \n",
      " 4   submitted       30000 non-null  datetime64[ns]\n",
      " 5   n_steps         30000 non-null  Int64         \n",
      " 6   description     29377 non-null  object        \n",
      " 7   n_ingredients   21120 non-null  float64       \n",
      "dtypes: Int64(1), datetime64[ns](1), float64(1), int64(3), object(2)\n",
      "memory usage: 3.1+ MB\n",
      "Сохранение словаря проведено успешно!\n"
     ]
    }
   ],
   "source": [
    "print(merge_table['n_steps'].isna().any(), \"- n_steps не содержит пропусков\")\n",
    "if merge_table['n_steps'].isna().any() == False:\n",
    "   merge_table=merge_table.astype({'n_steps' : 'Int64'})#recipes=recipes.astype({'submitted' : 'datetime64'})\n",
    "merge_table.info()\n",
    "merge_table.to_csv(cwd+'\\\\recipes_sample_with_filled_nsteps.csv')\n",
    "print(\"Сохранение словаря проведено успешно!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
